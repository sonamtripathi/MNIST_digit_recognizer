{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from notebook_importer import * ## This is used to import the functionality of one ipython notebook to other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from Digit_Recognizer_Deep_learning.ipynb\n",
      "importing notebook from Digit_recognizer_logistic_regression.ipynb\n",
      "importing notebook from Digit_recognizer_neural_network.ipynb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import Digit_Recognizer_Deep_learning\n",
    "import Digit_recognizer_logistic_regression\n",
    "import Digit_recognizer_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "    data = mnist.train.next_batch(8000)\n",
    "    train_x = data[0]\n",
    "    \n",
    "    #print(train_x)\n",
    "    #print(train_x.shape)\n",
    "    Y = data[1]\n",
    "    train_y = (np.arange(np.max(Y) + 1) == Y[:, None]).astype(int)\n",
    "    #print(train_y)\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=False)\n",
    "    tb = mnist.train.next_batch(2000)\n",
    "    Y_test = tb[1]\n",
    "    X_test = tb[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    d1 = Digit_recognizer_logistic_regression.model(train_x.T, train_y.T, Y,X_test.T, Y_test, num_iters = 1500, alpha = 0.05, print_cost = True)\n",
    "    w_LR = d1[\"w\"]\n",
    "    b_LR = d1[\"b\"]\n",
    "    \n",
    "    d2 = Digit_recognizer_neural_network.model_nn(train_x.T, train_y.T, Y, X_test.T, Y_test, n_h = 100, num_iters = 1500, alpha = 0.05, print_cost = True)\n",
    "    \n",
    "    dims = [784, 100, 80, 50, 10]\n",
    "    d3 = Digit_Recognizer_Deep_learning.model_DL(train_x.T, train_y.T, Y, X_test.T, Y_test,dims, alpha = 0.5, num_iterations = 1100, print_cost = True)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img, contours, thresh = get_img_contour_thresh(img)\n",
    "        ans1 = ''\n",
    "        ans2 = ''\n",
    "        ans3 = ''\n",
    "        \n",
    "        if len(contours) > 0:\n",
    "            contour = max(contours, key = cv2.contourArea)\n",
    "            if cv2.contourArea(contour) > 2500:\n",
    "                \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                newImage = thresh[y:y+h, x:x+w]\n",
    "                newImage = cv2.resize(newImage, (28,28))\n",
    "                newImage = np.array(newImage)\n",
    "                newImage = newImage.flatten()\n",
    "                newImage = newImage.reshape(newImage.shape[0], 1)\n",
    "                ans1 = Digit_recognizer_logistic_regression.predict(w_LR, b_LR, newImage)\n",
    "                ans2 = Digit_recognizer_neural_network.predict_nn(d2, newImage)\n",
    "                ans3 = Digit_Recognizer_Deep_learning.predict(d3, newImage)\n",
    "        \n",
    "        x, y, w, h = 0, 0, 300, 300\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(img, \"Logistic Regression : \" + str(ans1), (10 , 320), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255),2)\n",
    "        cv2.putText(img, \"Shallow Network : \" + str(ans2), (10,350), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(img, \"Deep Network : \" + str(ans3), (10,380), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        cv2.imshow(\"Contours\", thresh)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return(img, contours, thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Logistic Regression Result\n",
      "Cost after iteration 0: 2.302585\n",
      "Cost after iteration 50: 1.057471\n",
      "Cost after iteration 100: 0.779072\n",
      "Cost after iteration 150: 0.660265\n",
      "Cost after iteration 200: 0.592731\n",
      "Cost after iteration 250: 0.548336\n",
      "Cost after iteration 300: 0.516485\n",
      "Cost after iteration 350: 0.492260\n",
      "Cost after iteration 400: 0.473049\n",
      "Cost after iteration 450: 0.457332\n",
      "Cost after iteration 500: 0.444158\n",
      "Cost after iteration 550: 0.432899\n",
      "Cost after iteration 600: 0.423125\n",
      "Cost after iteration 650: 0.414528\n",
      "Cost after iteration 700: 0.406883\n",
      "Cost after iteration 750: 0.400020\n",
      "Cost after iteration 800: 0.393810\n",
      "Cost after iteration 850: 0.388151\n",
      "Cost after iteration 900: 0.382961\n",
      "Cost after iteration 950: 0.378177\n",
      "Cost after iteration 1000: 0.373745\n",
      "Cost after iteration 1050: 0.369620\n",
      "Cost after iteration 1100: 0.365767\n",
      "Cost after iteration 1150: 0.362155\n",
      "Cost after iteration 1200: 0.358758\n",
      "Cost after iteration 1250: 0.355554\n",
      "Cost after iteration 1300: 0.352524\n",
      "Cost after iteration 1350: 0.349650\n",
      "Cost after iteration 1400: 0.346920\n",
      "Cost after iteration 1450: 0.344320\n",
      "Train_accuracy: {} % 90.85\n",
      "Test accuracy: {} % 92.0\n",
      "Neural Network Result\n",
      "Cost after iteration for 0: 2.999270\n",
      "Cost after iteration for 100: 0.416793\n",
      "Cost after iteration for 200: 0.343217\n",
      "Cost after iteration for 300: 0.308759\n",
      "Cost after iteration for 400: 0.286342\n",
      "Cost after iteration for 500: 0.269584\n",
      "Cost after iteration for 600: 0.256076\n",
      "Cost after iteration for 700: 0.244648\n",
      "Cost after iteration for 800: 0.234643\n",
      "Cost after iteration for 900: 0.225666\n",
      "Cost after iteration for 1000: 0.217464\n",
      "Cost after iteration for 1100: 0.209869\n",
      "Cost after iteration for 1200: 0.202767\n",
      "Cost after iteration for 1300: 0.196078\n",
      "Cost after iteration for 1400: 0.189745\n",
      "Train accuracy: {} % 94.975\n",
      "Train accuracy: {} % 95.89999999999999\n",
      "Deep Network Result:\n",
      "Cost after iteration 0: 2.302588\n",
      "Cost after iteration 100: 2.300374\n",
      "Cost after iteration 200: 2.300351\n",
      "Cost after iteration 300: 2.300298\n",
      "Cost after iteration 400: 2.300047\n",
      "Cost after iteration 500: 2.086177\n",
      "Cost after iteration 600: 1.505291\n",
      "Cost after iteration 700: 1.163587\n",
      "Cost after iteration 800: 0.656481\n",
      "Cost after iteration 900: 0.282475\n",
      "Cost after iteration 1000: 0.327895\n",
      "Train accuracy: {} % 49.25\n",
      "Test accuracy: {} % 48.949999999999996\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
