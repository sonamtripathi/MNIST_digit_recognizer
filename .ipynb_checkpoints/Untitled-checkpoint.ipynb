{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import input_data\n",
    "import cv2\n",
    "from notebook_importer import * ## This is used to import the functionality of one ipython notebook to other\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from Digit_Recognizer_Deep_learning.ipynb\n",
      "importing notebook from Digit_recognizer_logistic_regression.ipynb\n",
      "importing notebook from Digit_recognizer_neural_network.ipynb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import Digit_Recognizer_Deep_learning\n",
    "import Digit_recognizer_logistic_regression\n",
    "import Digit_recognizer_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Logistic Regression Result\n",
      "Cost after iteration 0: 2.302585\n",
      "Cost after iteration 50: 1.057471\n",
      "Cost after iteration 100: 0.779072\n",
      "Cost after iteration 150: 0.660265\n",
      "Cost after iteration 200: 0.592731\n",
      "Cost after iteration 250: 0.548336\n",
      "Cost after iteration 300: 0.516485\n",
      "Cost after iteration 350: 0.492260\n",
      "Cost after iteration 400: 0.473049\n",
      "Cost after iteration 450: 0.457332\n",
      "Cost after iteration 500: 0.444158\n",
      "Cost after iteration 550: 0.432899\n",
      "Cost after iteration 600: 0.423125\n",
      "Cost after iteration 650: 0.414528\n",
      "Cost after iteration 700: 0.406883\n",
      "Cost after iteration 750: 0.400020\n",
      "Cost after iteration 800: 0.393810\n",
      "Cost after iteration 850: 0.388151\n",
      "Cost after iteration 900: 0.382961\n",
      "Cost after iteration 950: 0.378177\n",
      "Cost after iteration 1000: 0.373745\n",
      "Cost after iteration 1050: 0.369620\n",
      "Cost after iteration 1100: 0.365767\n",
      "Cost after iteration 1150: 0.362155\n",
      "Cost after iteration 1200: 0.358758\n",
      "Cost after iteration 1250: 0.355554\n",
      "Cost after iteration 1300: 0.352524\n",
      "Cost after iteration 1350: 0.349650\n",
      "Cost after iteration 1400: 0.346920\n",
      "Cost after iteration 1450: 0.344320\n",
      "Train_accuracy: {} % 90.85\n",
      "Test accuracy: {} % 92.0\n",
      "Neural Network Result\n",
      "Cost after iteration for 0: 2.999270\n",
      "Cost after iteration for 100: 0.416793\n",
      "Cost after iteration for 200: 0.343217\n",
      "Cost after iteration for 300: 0.308759\n",
      "Cost after iteration for 400: 0.286342\n",
      "Cost after iteration for 500: 0.269584\n",
      "Cost after iteration for 600: 0.256076\n",
      "Cost after iteration for 700: 0.244648\n",
      "Cost after iteration for 800: 0.234643\n",
      "Cost after iteration for 900: 0.225666\n",
      "Cost after iteration for 1000: 0.217464\n",
      "Cost after iteration for 1100: 0.209869\n",
      "Cost after iteration for 1200: 0.202767\n",
      "Cost after iteration for 1300: 0.196078\n",
      "Cost after iteration for 1400: 0.189745\n",
      "Train accuracy: {} % 94.975\n",
      "Train accuracy: {} % 95.89999999999999\n",
      "Deep Network Result:\n",
      "Cost after iteration 0: 2.302588\n",
      "Cost after iteration 100: 2.300374\n",
      "Cost after iteration 200: 2.300351\n",
      "Cost after iteration 300: 2.300298\n",
      "Cost after iteration 400: 2.300047\n",
      "Cost after iteration 500: 2.086177\n",
      "Cost after iteration 600: 1.505291\n",
      "Cost after iteration 700: 1.163587\n",
      "Cost after iteration 800: 0.656481\n",
      "Cost after iteration 900: 0.282475\n",
      "Cost after iteration 1000: 0.327895\n",
      "Train accuracy: {} % 49.25\n",
      "Test accuracy: {} % 48.949999999999996\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'deque' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e99d653a6be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e99d653a6be1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mLower_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mUpper_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m130\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mblackboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdigit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deque' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "    data = mnist.train.next_batch(8000)\n",
    "    train_x = data[0]\n",
    "    \n",
    "    #print(train_x)\n",
    "    #print(train_x.shape)\n",
    "    Y = data[1]\n",
    "    train_y = (np.arange(np.max(Y) + 1) == Y[:, None]).astype(int)\n",
    "    #print(train_y)\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=False)\n",
    "    tb = mnist.train.next_batch(2000)\n",
    "    Y_test = tb[1]\n",
    "    X_test = tb[0]\n",
    "    \n",
    "    d1 = Digit_recognizer_logistic_regression.model(train_x.T, train_y.T, Y, X_test.T, Y_test, num_iters=1500, alpha=0.05,\n",
    "                                   print_cost=True)\n",
    "    w_LR = d1[\"w\"]\n",
    "    b_LR = d1[\"b\"]\n",
    "\n",
    "    d2 = Digit_recognizer_neural_network.model_nn(train_x.T, train_y.T, Y, X_test.T, Y_test, n_h=100, num_iters=1500, alpha=0.05,\n",
    "                                      print_cost=True)\n",
    "\n",
    "    dims = [784, 100, 80, 50, 10]\n",
    "    d3 = Digit_Recognizer_Deep_learning.model_DL(train_x.T, train_y.T, Y, X_test.T, Y_test, dims, alpha=0.5, num_iterations=1100,\n",
    "                                      print_cost=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Lower_green = np.array([110, 50, 50])\n",
    "    Upper_green = np.array([130, 255, 255])\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "    flag = 0\n",
    "    ans1 = ''\n",
    "    ans2 = ''\n",
    "    ans3 = ''\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        center = None\n",
    "\n",
    "        if len(cnts) >= 1:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(cnt) > 200:\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "                M = cv2.moments(cnt)\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "                pts.appendleft(center)\n",
    "                for i in range(1, len(pts)):\n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "        elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "                blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "                if len(blackboard_cnts) >= 1:\n",
    "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                    print(cv2.contourArea(cnt))\n",
    "                    if cv2.contourArea(cnt) > 2000:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                        newImage = cv2.resize(digit, (28, 28))\n",
    "                        newImage = np.array(newImage)\n",
    "                        newImage = newImage.flatten()\n",
    "                        newImage = newImage.reshape(newImage.shape[0], 1)\n",
    "                        ans1 = Digit_Recognizer_LR.predict(w_LR, b_LR, newImage)\n",
    "                        ans2 = Digit_Recognizer_NN.predict_nn(d2, newImage)\n",
    "                        ans3 = Digit_Recognizer_DL.predict(d3, newImage)\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        cv2.putText(img, \"Logistic Regression : \" + str(ans1), (10, 410),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(img, \"Shallow Network :  \" + str(ans2), (10, 440),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(img, \"Deep Network :  \" + str(ans3), (10, 470),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
